# ğŸ› Debugging Guide - AI Features

## Added Comprehensive Logging

I've added detailed console logging throughout the entire AI pipeline to help identify where the 500 error is occurring.

### ğŸ¯ Logging Flow

When you make a request to the chat API, you'll now see detailed logs in this order:

```
1. ğŸš€ [CHAT API] Request started
   â”œâ”€ ğŸ“‹ Step 1: Validating API key
   â”œâ”€ ğŸ“‹ Step 2: Parsing request body
   â”œâ”€ ğŸ“‹ Step 3: Validating message
   â”œâ”€ ğŸ“‹ Step 4: Initializing StudyAssistantService
   â”œâ”€ ğŸ“‹ Step 5: Initializing with notes
   â””â”€ ğŸ“‹ Step 6: Calling assistant.ask()
       â”‚
       â”œâ”€ ğŸ¤– [STUDY ASSISTANT] ask() called
       â”œâ”€ ğŸ” Validating config
       â”œâ”€ ğŸ” Checking notes
       â”œâ”€ ğŸ”§ Getting LLM instance
       â”‚   â”‚
       â”‚   â”œâ”€ ğŸ”§ [BASE SERVICE] getLLM() called
       â”‚   â”œâ”€ ğŸ”‘ Checking API key
       â”‚   â”œâ”€ ğŸ—ï¸ Creating ChatOpenAI instance
       â”‚   â””â”€ âœ… ChatOpenAI instance created
       â”‚
       â”œâ”€ ğŸ” Finding relevant notes
       â”œâ”€ ğŸ“ Formatting context
       â”œâ”€ ğŸ“ Formatting history
       â”œâ”€ ğŸ”¨ Creating prompt template
       â”œâ”€ â›“ï¸ Creating chain
       â”œâ”€ ğŸš€ Invoking chain (calling AI)
       â”œâ”€ â±ï¸ This may take 10-30 seconds...
       â”œâ”€ âœ… Chain invoked successfully
       â”œâ”€ ğŸ“ Raw response length
       â”œâ”€ ğŸ§¹ Stripping thinking tags
       â”‚   â”‚
       â”‚   â”œâ”€ ğŸ§¹ [JSON EXTRACTOR] stripThinkingTags() called
       â”‚   â”œâ”€ ğŸ“ Input length
       â”‚   â”œâ”€ ğŸ” Has <think> tags
       â”‚   â”œâ”€ ğŸ“ Output length
       â”‚   â””â”€ âœ… stripThinkingTags() completed
       â”‚
       â””â”€ âœ… ask() completed successfully

   â””â”€ ğŸ“‹ Step 7: Sending response
       â””â”€ âœ… Request completed successfully
```

### ğŸ”¥ Error Logging

If an error occurs, you'll see detailed error information:

```
ğŸ’¥ [COMPONENT] ==================== ERROR ====================
âŒ Error caught in [location]
ğŸ” Error type: [type]
ğŸ” Error constructor: [name]
ğŸ“› Error name: [error.name]
ğŸ“› Error message: [error.message]
ğŸ“› Error stack: [full stack trace]
ğŸ·ï¸ Error category: [CONFIG/NETWORK/PROCESSING]
ğŸ’¥ ==========================================
```

## ğŸš€ How to Use for Debugging

### 1. Start Your Dev Server

```bash
npm run dev
```

### 2. Open Browser DevTools Console

- Open your app in the browser
- Press `F12` or `Cmd+Option+I` (Mac) / `Ctrl+Shift+I` (Windows)
- Go to "Console" tab

### 3. Also Monitor Terminal/Server Logs

The server console will show detailed logs. Watch BOTH:
- **Browser Console** - Frontend errors
- **Terminal Console** - Backend/API errors

### 4. Try Using the Chat Feature

Navigate to `/chat` and send a message. Watch the logs carefully.

## ğŸ” What to Look For

### Case 1: Error Before AI Call

If you see logs stop before "ğŸš€ Invoking chain", the issue is likely:

- âŒ API key not configured
- âŒ Notes not loading
- âŒ Service initialization failure

**Check:**
```bash
# Verify .env.local exists and has the key
cat .env.local | grep OPENROUTER_API_KEY
```

### Case 2: Error During AI Call

If you see "ğŸš€ Invoking chain" but no "âœ… Chain invoked successfully":

- âŒ Network issue connecting to OpenRouter
- âŒ API key invalid or rate limited
- âŒ Model not available

**Check:**
```bash
# Test OpenRouter API directly
curl https://openrouter.ai/api/v1/models \
  -H "Authorization: Bearer $OPENROUTER_API_KEY"
```

### Case 3: Error After AI Call

If you see "âœ… Chain invoked successfully" but still get a 500 error:

- âŒ Response parsing failure
- âŒ Thinking tags not being stripped correctly
- âŒ Empty response from AI

**Look for:**
- Raw response length = 0
- Cleaned response length = 0
- JSON parsing errors

### Case 4: Silent Failure

If logs stop suddenly without error:

- âŒ Unhandled promise rejection
- âŒ Timeout (AI took too long)
- âŒ Memory issue

**Check:**
- Browser Network tab for timeout
- Server memory usage
- Look for uncaught errors in console

## ğŸ“Š Log Symbols Guide

| Symbol | Meaning |
|--------|---------|
| ğŸš€ | Process starting |
| âœ… | Success/Completed |
| âŒ | Error/Failed |
| ğŸ“‹ | Step/Stage |
| ğŸ” | Checking/Validating |
| ğŸ”§ | Creating/Building |
| ğŸ“ | Processing data |
| ğŸ“ | Size/Length info |
| ğŸ”‘ | API key related |
| ğŸ¤– | AI/Model related |
| ğŸ’¥ | Critical error |
| âš ï¸ | Warning |
| ğŸ“¦ | Data/Payload |
| ğŸŒ | Network/URL |
| ğŸ§¹ | Cleaning/Parsing |

## ğŸ› ï¸ Common Issues & Solutions

### Issue 1: "OPENROUTER_API_KEY is not configured"

**Logs show:**
```
âŒ [CHAT API] OPENROUTER_API_KEY is not configured
```

**Solution:**
```bash
# Check if .env.local exists
ls -la .env.local

# If missing, create it:
echo "OPENROUTER_API_KEY=your-key-here" > .env.local

# Restart dev server
npm run dev
```

### Issue 2: Empty Response

**Logs show:**
```
âœ… Chain invoked successfully
ğŸ“ Raw response length: 0
```

**Possible causes:**
- Model returned empty response
- DeepSeek R1 output was only thinking tags
- Content filtering removed all content

**Solution:**
Check the raw response in logs. If it's all `<think>` tags, the model didn't provide an actual answer.

### Issue 3: Timeout

**Logs show nothing after:**
```
â±ï¸ This may take 10-30 seconds...
```

**Solution:**
- DeepSeek R1 can be slow (30+ seconds)
- Increase timeout in ChatInterface.tsx
- Try a faster model

### Issue 4: Network Error

**Logs show:**
```
ğŸ“› Error message: fetch failed
```

**Solution:**
```bash
# Check internet connection
ping openrouter.ai

# Check if OpenRouter is accessible
curl https://openrouter.ai/api/v1/models
```

### Issue 5: Rate Limiting

**Logs show:**
```
ğŸ“› Error message: Rate limit exceeded
```

**Solution:**
- Free tier has limits (20 requests/minute)
- Wait 60 seconds
- Upgrade to paid tier
- Use a different model

## ğŸ“± Testing Commands

### Test Chat API Directly

```bash
curl -X POST http://localhost:3000/api/ai/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Hello",
    "notes": [
      {
        "id": "1",
        "title": "Test",
        "content": "Test content",
        "tags": []
      }
    ]
  }'
```

### Monitor Logs in Real-Time

```bash
# In one terminal
npm run dev | grep -E "(ğŸš€|âœ…|âŒ|ğŸ’¥)"

# In another terminal
# Use the app and watch logs
```

### Check All AI Endpoints

```bash
# Summarize
curl -X POST http://localhost:3000/api/ai/summarize \
  -H "Content-Type: application/json" \
  -d '{"title":"Test","content":"Test content","maxLength":"short"}'

# Chat
curl -X POST http://localhost:3000/api/ai/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Hello","notes":[]}'
```

## ğŸ¯ Next Steps

1. **Start your dev server** with `npm run dev`
2. **Open your browser console** (F12)
3. **Navigate to** `http://localhost:3000/chat`
4. **Send a test message**
5. **Copy all logs** from both browser and terminal
6. **Share the logs** so we can pinpoint the exact error

## ğŸ“‹ Log Collection Template

When reporting an issue, provide:

```
### Browser Console Logs
[Paste browser console output here]

### Server/Terminal Logs
[Paste terminal output here]

### Request Details
- Message sent: [your message]
- Number of notes: [count]
- Timestamp: [when error occurred]

### Environment
- Node version: [run: node -v]
- npm version: [run: npm -v]
- OS: [your OS]
```

## ğŸ”’ Security Note

When sharing logs:
- âœ… Logs are safe to share (API key length shown, not actual key)
- âš ï¸ Don't share the actual API key value
- âš ï¸ Don't share personal note content
